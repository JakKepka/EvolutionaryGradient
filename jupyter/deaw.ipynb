{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DEAW"
      ],
      "metadata": {
        "id": "UygnAJUTvfra"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xjrbqhCvvMTI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Załaduj zbiór danych Iris\n",
        "iris = load_wine()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=42)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=13, hidden_size=16, output_size=3):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Funkcja oceny (fitness)\n",
        "def fitness(weights, model, train_loader, device):\n",
        "    idx = 0\n",
        "    for param in model.parameters():\n",
        "        numel = param.numel()\n",
        "        param.data = weights[idx:idx+numel].view(param.size()).to(device)\n",
        "        idx += numel\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "# Algorytm DEAW\n",
        "def train_deaw(model, train_loader, device, NP=50, F=0.5, CR=0.9, max_generations=100, initial_lower=-1.0, initial_upper=1.0):\n",
        "    num_weights = sum(p.numel() for p in model.parameters())\n",
        "    lower_bounds = np.full(num_weights, initial_lower)\n",
        "    upper_bounds = np.full(num_weights, initial_upper)\n",
        "    population = np.random.uniform(initial_lower, initial_upper, (NP, num_weights))\n",
        "    fitnesses = np.array([fitness(torch.tensor(p, dtype=torch.float32), model, train_loader, device) for p in population])\n",
        "\n",
        "    for generation in range(max_generations):\n",
        "        for i in range(NP):\n",
        "            candidates = [j for j in range(NP) if j != i]\n",
        "            a, b, c = np.random.choice(candidates, 3, replace=False)\n",
        "            v = population[a] + F * (population[b] - population[c])\n",
        "\n",
        "            for j in range(num_weights):\n",
        "                if v[j] < lower_bounds[j]:\n",
        "                    lower_bounds[j] *= 3\n",
        "                    v[j] = lower_bounds[j]\n",
        "                elif v[j] > upper_bounds[j]:\n",
        "                    upper_bounds[j] *= 3\n",
        "                    v[j] = upper_bounds[j]\n",
        "\n",
        "            u = np.copy(population[i])\n",
        "            j_rand = np.random.randint(0, num_weights)\n",
        "            for j in range(num_weights):\n",
        "                if np.random.rand() < CR or j == j_rand:\n",
        "                    u[j] = v[j]\n",
        "\n",
        "            u_tensor = torch.tensor(u, dtype=torch.float32)\n",
        "            loss_u = fitness(u_tensor, model, train_loader, device)\n",
        "\n",
        "            if loss_u < fitnesses[i]:\n",
        "                population[i] = u.copy()\n",
        "                fitnesses[i] = loss_u\n",
        "\n",
        "    best_idx = np.argmin(fitnesses)\n",
        "    best_weights = torch.tensor(population[best_idx], dtype=torch.float32)\n",
        "    idx = 0\n",
        "    for param in model.parameters():\n",
        "        numel = param.numel()\n",
        "        param.data = best_weights[idx:idx+numel].view(param.size()).to(device)\n",
        "        idx += numel\n",
        "\n",
        "# Użycie\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP().to(device)\n",
        "train_deaw(model, train_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "accuracy = evaluate_model(model, test_loader, device)\n",
        "print(f\"Dokładność na zbiorze testowym: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzLjXlh2x0AY",
        "outputId": "4205fde0-63ee-41a9-be14-d0958a5ed828"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dokładność na zbiorze testowym: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_de(model, train_loader, device, NP=50, F=0.5, CR=0.9, max_generations=100, initial_lower=-1.0, initial_upper=1.0):\n",
        "    num_weights = sum(p.numel() for p in model.parameters())\n",
        "    population = np.random.uniform(initial_lower, initial_upper, (NP, num_weights))\n",
        "    fitnesses = np.array([fitness(torch.tensor(p, dtype=torch.float32), model, train_loader, device) for p in population])\n",
        "\n",
        "    for generation in range(max_generations):\n",
        "        for i in range(NP):\n",
        "            candidates = [j for j in range(NP) if j != i]\n",
        "            a, b, c = np.random.choice(candidates, 3, replace=False)\n",
        "            v = population[a] + F * (population[b] - population[c])\n",
        "\n",
        "            # Stałe ograniczenie: ograniczamy wartości do zakresu\n",
        "            v = np.clip(v, initial_lower, initial_upper)\n",
        "\n",
        "            u = np.copy(population[i])\n",
        "            j_rand = np.random.randint(0, num_weights)\n",
        "            for j in range(num_weights):\n",
        "                if np.random.rand() < CR or j == j_rand:\n",
        "                    u[j] = v[j]\n",
        "\n",
        "            u_tensor = torch.tensor(u, dtype=torch.float32)\n",
        "            loss_u = fitness(u_tensor, model, train_loader, device)\n",
        "\n",
        "            if loss_u < fitnesses[i]:\n",
        "                population[i] = u.copy()\n",
        "                fitnesses[i] = loss_u\n",
        "\n",
        "    best_idx = np.argmin(fitnesses)\n",
        "    best_weights = torch.tensor(population[best_idx], dtype=torch.float32)\n",
        "    idx = 0\n",
        "    for param in model.parameters():\n",
        "        numel = param.numel()\n",
        "        param.data = best_weights[idx:idx+numel].view(param.size()).to(device)\n",
        "        idx += numel\n"
      ],
      "metadata": {
        "id": "KaPDfg5Ux2Gx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_de = MLP().to(device)\n",
        "train_de(model_de, train_loader, device)\n",
        "accuracy_de = evaluate_model(model_de, test_loader, device)\n",
        "print(f\"[DE] Dokładność na zbiorze testowym: {accuracy_de:.2f}%\")\n"
      ],
      "metadata": {
        "id": "UhavMND098YU",
        "outputId": "71f25476-a8d3-44ba-959d-20e7507430f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DE] Dokładność na zbiorze testowym: 66.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDEADAM"
      ],
      "metadata": {
        "id": "Se7E7wsRuD57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.stats import cauchy\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "# FFNN for Iris dataset (4-9-3 architecture)\n",
        "class FFNN(nn.Module):\n",
        "    def __init__(self, input_size=4, hidden_size=9, output_size=3):\n",
        "        super(FFNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)  # Includes bias\n",
        "        self.layer2 = nn.Linear(hidden_size, output_size)  # Includes bias\n",
        "        # Initialize weights in [-1, 1]\n",
        "        nn.init.uniform_(self.layer1.weight, -1, 1)\n",
        "        nn.init.uniform_(self.layer2.weight, -1, 1)\n",
        "        nn.init.uniform_(self.layer1.bias, -1, 1)\n",
        "        nn.init.uniform_(self.layer2.bias, -1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = sigmoid(self.layer1(x))  # Bias included in layer1\n",
        "        x = self.layer2(x)  # Bias included in layer2, no sigmoid on output for MSE\n",
        "        return x\n",
        "\n",
        "    def get_weights(self):\n",
        "        # Flatten weights and biases into a vector\n",
        "        return torch.cat([\n",
        "            self.layer1.weight.flatten(),\n",
        "            self.layer1.bias.flatten(),\n",
        "            self.layer2.weight.flatten(),\n",
        "            self.layer2.bias.flatten()\n",
        "        ])\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        # Set weights from a flat vector\n",
        "        idx = 0\n",
        "        w1_size = self.input_size * self.hidden_size\n",
        "        self.layer1.weight.data = weights[idx:idx+w1_size].reshape(self.hidden_size, self.input_size)\n",
        "        idx += w1_size\n",
        "        self.layer1.bias.data = weights[idx:idx+self.hidden_size]\n",
        "        idx += self.hidden_size\n",
        "        w2_size = self.hidden_size * self.output_size\n",
        "        self.layer2.weight.data = weights[idx:idx+w2_size].reshape(self.output_size, self.hidden_size)\n",
        "        idx += w2_size\n",
        "        self.layer2.bias.data = weights[idx:idx+self.output_size]\n",
        "\n",
        "# Compute MSE loss\n",
        "def compute_mse(model, inputs, targets):\n",
        "    outputs = model(inputs)\n",
        "    mse = torch.mean((outputs - targets) ** 2)\n",
        "    return mse.item()\n",
        "\n",
        "# Population-based Adam (P-Adam)\n",
        "class PAdam:\n",
        "    def __init__(self, population, alpha=0.1, gamma1=0.9, gamma2=0.99, gamma3=0.999, tau=1e-7):\n",
        "        self.population = population\n",
        "        self.alpha = alpha\n",
        "        self.gamma1 = gamma1\n",
        "        self.gamma2 = gamma2\n",
        "        self.gamma3 = gamma3\n",
        "        self.tau = tau\n",
        "        self.m = [torch.zeros_like(ind) for ind in population]  # First moment\n",
        "        self.n = [torch.zeros_like(ind) for ind in population]  # Second moment\n",
        "\n",
        "    def step(self, model, inputs, targets, t):\n",
        "        new_population = []\n",
        "        fitnesses = []\n",
        "        for i, (ind, m_i, n_i) in enumerate(zip(self.population, self.m, self.n)):\n",
        "            model.set_weights(ind)\n",
        "            outputs = model(inputs)\n",
        "            loss = torch.mean((outputs - targets) ** 2)\n",
        "            loss.backward()\n",
        "\n",
        "            # Compute gradients\n",
        "            grads = torch.cat([\n",
        "                model.layer1.weight.grad.flatten(),\n",
        "                model.layer1.bias.grad.flatten(),\n",
        "                model.layer2.weight.grad.flatten(),\n",
        "                model.layer2.bias.grad.flatten()\n",
        "            ])\n",
        "\n",
        "            # Update moments\n",
        "            m_i = self.gamma1 * m_i + (1 - self.gamma1) * grads\n",
        "            n_i = self.gamma2 * n_i + (1 - self.gamma3) * (grads ** 2)\n",
        "\n",
        "            # Bias correction\n",
        "            m_hat = m_i / (1 - self.gamma1 ** t)\n",
        "            n_hat = n_i / (1 - self.gamma3 ** t)\n",
        "\n",
        "            # Update parameters\n",
        "            new_ind = ind - self.alpha * m_hat / (torch.sqrt(n_hat) + self.tau)\n",
        "            new_population.append(new_ind)\n",
        "            fitnesses.append(compute_mse(model, inputs, targets))\n",
        "\n",
        "            # Zero gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            self.m[i] = m_i\n",
        "            self.n[i] = n_i\n",
        "\n",
        "        self.population = new_population\n",
        "        return fitnesses\n",
        "\n",
        "# Modified CoBiDE (M-CoBiDE)\n",
        "class MCoBiDE:\n",
        "    def __init__(self, population, pb=0.5, ps=0.4):\n",
        "        self.population = population\n",
        "        self.pb = pb\n",
        "        self.ps = ps\n",
        "        self.rng = np.random.default_rng()\n",
        "        self.F = [self._sample_F() for _ in population]\n",
        "        self.CR = [self._sample_CR() for _ in population]\n",
        "\n",
        "    def _sample_F(self):\n",
        "        r = self.rng.random()\n",
        "        if r < 0.5:\n",
        "            return cauchy.rvs(loc=0.65, scale=0.1, random_state=self.rng)\n",
        "        else:\n",
        "            return cauchy.rvs(loc=1.0, scale=0.1, random_state=self.rng)\n",
        "\n",
        "    def _sample_CR(self):\n",
        "        r = self.rng.random()\n",
        "        if r < 0.5:\n",
        "            cr = cauchy.rvs(loc=0.1, scale=0.1, random_state=self.rng)\n",
        "        else:\n",
        "            cr = cauchy.rvs(loc=0.95, scale=0.1, random_state=self.rng)\n",
        "        return np.clip(cr, 0, 1)\n",
        "\n",
        "    def step(self, model, inputs, targets):\n",
        "        fitnesses = [compute_mse(model, inputs, targets) for ind in self.population]\n",
        "        best_idx = np.argmin(fitnesses)\n",
        "        new_population = []\n",
        "\n",
        "        # Compute covariance matrix for top ps proportion\n",
        "        top_indices = np.argsort(fitnesses)[:int(self.ps * len(self.population))]\n",
        "        top_pop = torch.stack([self.population[i] for i in top_indices])\n",
        "        cov = torch.cov(top_pop.T)\n",
        "        cov += 1e-6 * torch.eye(cov.shape[0])  # Add perturbation for stability\n",
        "        eigvals, eigvecs = torch.linalg.eigh(cov)\n",
        "        P = eigvecs\n",
        "\n",
        "        for i, (ind, F_i, CR_i) in enumerate(zip(self.population, self.F, self.CR)):\n",
        "            r1, r2 = self.rng.choice([j for j in range(len(self.population)) if j != i], 2, replace=False)\n",
        "            v_i = ind + F_i * (self.population[best_idx] - ind) + F_i * (self.population[r1] - self.population[r2])\n",
        "\n",
        "            r3 = self.rng.random()\n",
        "            if r3 >= self.pb:\n",
        "                u_i = ind.clone()\n",
        "                j_rand = self.rng.integers(0, len(ind))\n",
        "                for j in range(len(ind)):\n",
        "                    if self.rng.random() <= CR_i or j == j_rand:\n",
        "                        u_i[j] = v_i[j]\n",
        "            else:\n",
        "                x_prime = P.T @ ind\n",
        "                v_prime = P.T @ v_i\n",
        "                u_prime = x_prime.clone()\n",
        "                j_rand = self.rng.integers(0, len(ind))\n",
        "                for j in range(len(ind)):\n",
        "                    if self.rng.random() <= CR_i or j == j_rand:\n",
        "                        u_prime[j] = v_prime[j]\n",
        "                u_i = P @ u_prime\n",
        "\n",
        "            model.set_weights(u_i)\n",
        "            u_fitness = compute_mse(model, inputs, targets)\n",
        "            if u_fitness < fitnesses[i]:\n",
        "                new_population.append(u_i)\n",
        "                self.F[i] = self._sample_F()\n",
        "                self.CR[i] = self._sample_CR()\n",
        "            else:\n",
        "                new_population.append(ind)\n",
        "\n",
        "        self.population = new_population\n",
        "        return fitnesses\n",
        "\n",
        "# EDEAdam Algorithm\n",
        "class EDEAdam:\n",
        "    def __init__(self, model, pop_size=50, max_evals=25000, exchange_interval=5):\n",
        "        self.model = model\n",
        "        self.pop_size = pop_size\n",
        "        self.max_evals = max_evals\n",
        "        self.exchange_interval = exchange_interval\n",
        "        self.dim = sum(p.numel() for p in model.parameters())\n",
        "        # Verify dimension\n",
        "        expected_dim = model.input_size * model.hidden_size + model.hidden_size + model.hidden_size * model.output_size + model.output_size\n",
        "        assert self.dim == expected_dim, f\"Dimension mismatch: got {self.dim}, expected {expected_dim}\"\n",
        "        # Initialize population\n",
        "        self.population = [torch.rand(self.dim) * 2 - 1 for _ in range(pop_size)]\n",
        "        self.sub_pop1 = self.population[:pop_size//2]\n",
        "        self.sub_pop2 = self.population[pop_size//2:]\n",
        "        self.p_adam = PAdam(self.sub_pop1)\n",
        "        self.m_cobide = MCoBiDE(self.sub_pop2)\n",
        "\n",
        "    def run(self, inputs, targets):\n",
        "        t = 1\n",
        "        eval_count = 0\n",
        "        best_fitness = float('inf')\n",
        "        best_individual = None\n",
        "\n",
        "        while eval_count < self.max_evals:\n",
        "            fitness1 = self.p_adam.step(self.model, inputs, targets, t)\n",
        "            fitness2 = self.m_cobide.step(self.model, inputs, targets)\n",
        "            eval_count += len(self.sub_pop1) + len(self.sub_pop2)\n",
        "\n",
        "            best_idx1, worst_idx1 = np.argmin(fitness1), np.argmax(fitness1)\n",
        "            best_idx2, worst_idx2 = np.argmin(fitness2), np.argmax(fitness2)\n",
        "\n",
        "            if min(fitness1 + fitness2) < best_fitness:\n",
        "                best_fitness = min(fitness1 + fitness2)\n",
        "                best_individual = self.sub_pop1[best_idx1] if fitness1[best_idx1] < fitness2[best_idx2] else self.sub_pop2[best_idx2]\n",
        "\n",
        "            if t % self.exchange_interval == 0:\n",
        "                if fitness1[best_idx1] < fitness2[worst_idx2]:\n",
        "                    self.sub_pop2[worst_idx2] = self.sub_pop1[best_idx1].clone()\n",
        "                if fitness2[best_idx2] < fitness1[worst_idx1]:\n",
        "                    self.sub_pop1[worst_idx1] = self.sub_pop2[best_idx2].clone()\n",
        "\n",
        "            t += 1\n",
        "\n",
        "        self.model.set_weights(best_individual)\n",
        "        return best_fitness, eval_count\n",
        "\n"
      ],
      "metadata": {
        "id": "j_s6i_g89_tU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00667a15-668d-42ab-9552-955e41e214fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Fitness (MSE): 0.007978\n",
            "Training Accuracy: 42.86%\n",
            "Test Accuracy: 28.89%\n",
            "Evaluations Used: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    iris = load_iris()\n",
        "    X = torch.tensor(StandardScaler().fit_transform(iris.data), dtype=torch.float32)\n",
        "    y = torch.tensor(np.eye(3)[iris.target], dtype=torch.float32)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify = y, test_size=0.3, random_state=42)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    model = FFNN()\n",
        "    ede_adam = EDEAdam(model, pop_size=5000, max_evals=250000)\n",
        "\n",
        "    final_fitness, evals = ede_adam.run(X_train, y_train)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_pred = model(X_train)\n",
        "        train_acc = (train_pred.argmax(dim=1) == y_train.argmax(dim=1)).float().mean().item() * 100\n",
        "        test_pred = model(X_test)\n",
        "        test_acc = (test_pred.argmax(dim=1) == y_test.argmax(dim=1)).float().mean().item() * 100\n",
        "\n",
        "    print(f\"Final Fitness (MSE): {final_fitness:.6f}\")\n",
        "    print(f\"Training Accuracy: {train_acc:.2f}%\")\n",
        "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "    print(f\"Evaluations Used: {evals}\")\n"
      ],
      "metadata": {
        "id": "jn1KWCvMuPjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PiQUaNZwuP3d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}